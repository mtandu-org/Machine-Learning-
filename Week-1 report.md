# Machine-Learning ParrotAiIPT week 1 report
On starting day, we had a friendly introduction to get to know each other,which then we decide a proposed schedule for the week and here i was starting to gear my week in ML.I learned alot about ML from different source include proposed books and online courses,Here i came with this from those resources.. Machine learning which is the teqnique to program a computer to learn through data.
it has different types which are:
   Supervised learning,unsupervised,semi supervised learning and reinfocement learning
* in supervised learning we train our data to predict a new /unseen data with both input and output data
* in unsupervised learning we use unlabeled data to transform the interest in those data
* In reinfocement learning agent tend to perceive its enviroment and choose the action based on maximizing the reward.
 
On going i learned about  both classification and regression problems from supervised leraning here i grasp the knowledge to understand which kind of problem could be either classification and regression in which :
* classification problem this train a model to do predition of with descrete output.it seems like yes/no preblem which can be solved with different ML models includeLiner regression, Logistic regression,K-nearest neighbor,Random forest,Decision Tree,support vector machine and neural net
* Regression problem we train our model to predict continous value or float points values.this can be solved by the ML models which are Linear regression and logistic regression.[see more](https://github.com/mtandu-org/Machine-Learning-/edit/master/introduction%20to%20ML.md)
 
More so I jumped over Unsupervised learning problem,this is where the full meaning of differentiate supervised from unsupervised learning and trying to understand different unsupervised learning problem as i mentioned a little bit about it below. Unsupervised Learning problem:this include clusstering ,Dimensionality reduction and Association Rule
* clustering algorithm:its train unlabeled data and clustering a data with similar characteristics .this can be solved with ML modes like K-Means ,Hierachical clustering Algorithm and Expected maximization
* Dimensionality Reduction:is the simplification of a data without loss of information 
* Association Rule :is the rule that express that if an event occur there is probability of other 
   event to occur. which can be solved by Apriori.
   
Reinforcement Learning This was a little bit easier to me because i learned it in my Artificial interlligent cause  and was short part like introducing about agents ,enviroment and actions after perciving its enviroment by different sensors that agent have to optimize the rewards. these may be seen in different agent AlphaGo,self driving cars,Alexa and so on. And here i got the muscles on semi supervised learning in which trying to tell oubout having a model with alot of unlabed data and a bit of labed data, as you can see combines both supervised by having unlabed data on it and other hand is supervised.This could be seen on photo hosting engine like google photos. [see more](https://github.com/mtandu-org/Machine-Learning-/edit/master/introduction%20to%20ML.md)

Few days back I learned about Feature engineering which are techinique to choose the best feature to use in your data set,This can be done either by feature extraction and feature selection ,in which in feature selection we choose the best feature in our data set to train our model which can be achived by automatic feature selection like Univariate feature selection,model based feature selection and iterative feature selection which train model to remove recusive features in your dataset.

Also, we desicused about our proposed project which is about strawbery grading and quality control and brainstorming on how it will going to operate and what skill sets we must aquire in order to achive a project ,here have came with some hints which the project will base on both ML and hardware parts in which in ML we must have a model that can verify a fruit passed to test its really strawberry then it can grade it using the features extracted in that stawberry,Then feedback will be pushed on hardware and from there it can decide where to squize the stawberry based on its grade.

Further watches,it's about K Nearest Neighbor is the machine learning model train a model to determine a new unseen data belongs to which class in a training classes by cheking the ecludian distance between new data and the trained data by using the number of K with can be odd if your class is even to prevent equal votes in your model,More so implementation of it in python with both Iris dataset and Boston house price dataset.

Finally,It was about a week 1 challenge. it was a bit tough with alot of interrogation and this is because it has been different with the challenges i used to work with by having a single dataset which is then we split that dataset in both training and test set with the help of sklearn library,then its easier to verify your testing perfomance by having the test taget data by comparing with those predicted one, beside that I learned practical feature engineering where in my task i use 
to check feature coralation with tagets to chose the features to train our model on top of that I grasp the knowledge on how to change categorical variable to numerical.

Conlusive the week was tiresome because I'm still catching up with mode of learning ,intensive self learning and daily presantation of what you have learn to others but i really enjoying it because I have got alot through this. 


